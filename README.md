# Verisum

**Get concise, sourced answers from any website** - A Chrome extension that uses AI to answer questions about web pages.

## Features

### ğŸ¯ Core Functionality

- **Instant Answers**: Ask questions about any webpage and get AI-powered answers with cited sources
- **Smart Search**: Vector-based search finds the most relevant content on the page
- **Source Citations**: Every answer includes clickable sources that highlight the referenced text
- **Streaming Responses**: See answers appear in real-time as the AI generates them

### ğŸ’¡ User Interface

#### Popup (Click Extension Icon)

- **Suggested Questions**: 4 smart suggestions based on common queries
- **Query History**: Access your last 10 queries with dropdown
- **Copy Options**: Copy answer only or answer with sources
- **Quality Indicators**: Confidence badges (High/Medium/Low) based on source count
- **Loading Progress**: Multi-stage progress bar with percentages
- **Error Handling**: Specific error messages with retry button

#### Spotlight (Alt+Space)

- **Quick Access**: Overlay that appears on any page
- **Persistent State**: Reopens with your last question and answer
- **Keyboard Navigation**: Arrow keys to navigate sources, Enter to select
- **Auto-focus**: Input refocuses after answer for immediate follow-up questions
- **Markdown Support**: Bold, italic, code, and links in answers

### âŒ¨ï¸ Keyboard Shortcuts

- **Alt+Space**: Open Spotlight search
- **Ctrl+Shift+V** (Cmd+Shift+V on Mac): Open popup
- **Escape**: Close Spotlight
- **â†‘/â†“**: Navigate through sources
- **Enter**: Select/highlight source on page

### ğŸ¨ UX Improvements

- Multi-stage progress indicators during initialization
- Visual feedback with hover effects and animations
- Source click animations with pulse effect
- Streaming answer animations
- Quality confidence badges
- Source count indicators
- Copy buttons with success feedback

## Project Structure

```
verisum/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ @types/                    # TypeScript definitions
â”‚   â”‚   â”œâ”€â”€ global.d.ts
â”‚   â”‚   â””â”€â”€ vite.d.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ contentScript/             # Content script (runs on web pages)
â”‚   â”‚   â”œâ”€â”€ App.tsx                # Voice mode component (hold Space)
â”‚   â”‚   â”œâ”€â”€ App.module.css
â”‚   â”‚   â”œâ”€â”€ Spotlight.tsx          # Quick search overlay (Alt+Space)
â”‚   â”‚   â”œâ”€â”€ Spotlight.module.css
â”‚   â”‚   â”œâ”€â”€ Sources.tsx            # Source citations component
â”‚   â”‚   â”œâ”€â”€ Sources.module.css
â”‚   â”‚   â””â”€â”€ contentScript.ts       # Entry point, spotlight management
â”‚   â”‚
â”‚   â”œâ”€â”€ popup/                     # Extension popup (click icon)
â”‚   â”‚   â”œâ”€â”€ App/
â”‚   â”‚   â”‚   â”œâ”€â”€ Form.tsx           # Query input with suggestions & history
â”‚   â”‚   â”‚   â”œâ”€â”€ Form.module.css
â”‚   â”‚   â”‚   â”œâ”€â”€ Result.tsx         # Answer display with sources
â”‚   â”‚   â”‚   â”œâ”€â”€ Result.module.css
â”‚   â”‚   â”‚   â”œâ”€â”€ Footer.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Footer.module.css
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â”œâ”€â”€ document.css       # Global styles
â”‚   â”‚   â”‚   â”œâ”€â”€ reset.css
â”‚   â”‚   â”‚   â””â”€â”€ typography.css
â”‚   â”‚   â”œâ”€â”€ App.tsx                # Main popup logic
â”‚   â”‚   â”œâ”€â”€ App.module.css
â”‚   â”‚   â”œâ”€â”€ Initializer.tsx        # Loading/initialization screen
â”‚   â”‚   â”œâ”€â”€ Initializer.module.css
â”‚   â”‚   â”œâ”€â”€ popup.tsx              # Entry point
â”‚   â”‚   â””â”€â”€ popup.module.css
â”‚   â”‚
â”‚   â”œâ”€â”€ serviceWorker/             # Background service worker
â”‚   â”‚   â”œâ”€â”€ serviceWorker.ts       # Main service worker logic
â”‚   â”‚   â””â”€â”€ vectorDB.ts            # Vector database + AI integration
â”‚   â”‚
â”‚   â”œâ”€â”€ helpers/                   # Shared utilities
â”‚   â”‚   â”œâ”€â”€ chromeMessages.ts      # Chrome extension messaging
â”‚   â”‚   â”œâ”€â”€ classnames.ts          # CSS class utilities
â”‚   â”‚   â”œâ”€â”€ extractWebsiteParts.ts # DOM content extraction
â”‚   â”‚   â”œâ”€â”€ getPrompt.ts           # AI prompt generation
â”‚   â”‚   â”œâ”€â”€ highlightParagraph.ts  # Source highlighting on page
â”‚   â”‚   â”œâ”€â”€ SpeechToText.ts        # Voice input (experimental)
â”‚   â”‚   â”œâ”€â”€ textToSpeech.ts        # Voice output (experimental)
â”‚   â”‚   â”œâ”€â”€ types.ts               # TypeScript types
â”‚   â”‚   â””â”€â”€ VectorDB.ts            # Vector database client
â”‚   â”‚
â”‚   â”œâ”€â”€ theme/                     # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ Loader/
â”‚   â”‚   â”‚   â”œâ”€â”€ Loader.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Loader.module.css
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ icons/                     # Extension icons
â”‚   â”‚   â”œâ”€â”€ 16x.png
â”‚   â”‚   â”œâ”€â”€ 32x.png
â”‚   â”‚   â”œâ”€â”€ 48x.png
â”‚   â”‚   â””â”€â”€ 128x.png
â”‚   â”‚
â”‚   â””â”€â”€ popup.html                 # Popup HTML template
â”‚
â”œâ”€â”€ dist/                          # Build output (generated)
â”œâ”€â”€ .env.example                   # Environment variables template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ vite.config.ts                 # Build configuration + manifest
â””â”€â”€ README.md
```

## Architecture

### Component Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Interface                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Popup (Icon)       â”‚   Spotlight (Alt+Space)              â”‚
â”‚   - Suggestions      â”‚   - Quick overlay                    â”‚
â”‚   - History          â”‚   - Persistent state                 â”‚
â”‚   - Copy features    â”‚   - Keyboard nav                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Content Script Layer                     â”‚
â”‚   - Extract page content (h1-6, p tags)                     â”‚
â”‚   - Handle user interactions                                â”‚
â”‚   - Highlight sources on page                               â”‚
â”‚   - State management                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Service Worker (Background)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   VectorDB:                                                 â”‚
â”‚   - Xenova/all-MiniLM-L6-v2 (WASM, q8 quantization)         â”‚
â”‚   - Generate embeddings for page paragraphs                 â”‚
â”‚   - Vector search (top 7 results, 0.5 threshold)            â”‚ 
â”‚   - Cache: 1 hour TTL, URL-validated                        â”‚
â”‚                                                             â”‚
â”‚   AI Integration:                                           â”‚
â”‚   - Stream responses from OpenAI-compatible API             â”‚
â”‚   - Query cache: 30 min TTL                                 â”‚
â”‚   - Token optimization (~350 tokens per query)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External AI Service                      â”‚
â”‚   - OpenAI-compatible API endpoint                          â”‚
â”‚   - Model: claude-3-5-haiku-20241022 (configurable)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Page Load**: Content script extracts page content (h1-6, p tags)
2. **Embedding**: Service worker generates vector embeddings for all paragraphs
3. **Caching**: Embeddings cached in chrome.storage.local (1 hour TTL)
4. **Query**: User asks question in popup or spotlight
5. **Search**: Vector search finds top 7 most relevant paragraphs
6. **AI Request**: Relevant paragraphs + query sent to AI API
7. **Stream**: Answer streams back through service worker
8. **Display**: UI shows answer with source citations
9. **Interaction**: User can click sources to highlight on page

### Storage

**chrome.storage.local**:

- `verisum_last_query`: Last popup query, answer, and sources
- `verisum_query_history`: Last 10 queries (popup only)
- `{url}:{contentHash}`: Cached VectorDB embeddings (1 hour TTL)

**In-memory (Service Worker)**:

- Query result cache (30 min TTL)
- VectorDB model and entries

**In-memory (Content Script)**:

- Spotlight state (query, answer, sources) - persists until page navigation

## Technologies

### Core

- **Preact**: Lightweight React alternative for UI
- **TypeScript**: Type-safe JavaScript
- **Vite**: Fast build tool
- **CRXJS**: Chrome extension plugin for Vite

### AI/ML

- **Transformers.js (Xenova)**: Browser-based ML model execution
- **all-MiniLM-L6-v2**: Sentence embeddings model (WASM, quantized)
- **Vector Search**: Cosine similarity for semantic search

### UI/UX

- **CSS Modules**: Scoped styling
- **Lucide Icons**: Icon library
- **Showdown**: Markdown to HTML conversion (popup)

### Chrome APIs

- **chrome.storage.local**: Persistent caching
- **chrome.runtime**: Service worker messaging
- **chrome.commands**: Keyboard shortcuts
- **chrome.action**: Extension popup

## Performance

### Bundle Sizes

- **Content Script**: ~12 KB (includes UI components)
- **Popup**: ~84 KB (includes form logic, history, suggestions)
- **Service Worker**: ~743 KB (includes ML model)

### Optimizations

- **Token Reduction**: Send only top 7 paragraphs (~350 tokens vs ~10,000)
- **Query Caching**: 30 min TTL for instant repeated queries
- **VectorDB Caching**: 1 hour TTL with URL validation
- **Lazy Loading**: Models load on-demand
- **WASM Acceleration**: Fast embeddings generation
- **Quantization**: q8 model for smaller size

### Response Times

- **Cached Query**: <100ms
- **Fresh Query**: 1-3s (vector search + AI generation)
- **First-Time Load**: 10-30s (model download, first run only)

## Configuration

The extension uses environment variables for API configuration. Copy `.env.example` to `.env` and configure:

```bash
# OpenAI-compatible API endpoint
VITE_API_URL=http://192.168.110.114:4000

# Model name
VITE_MODEL_NAME=claude-3-5-haiku-20241022
```

These are embedded at build time via Vite.

## Development

### Setup

```bash
npm install
```

### Build

```bash
npm run build
```

Output: `dist/` directory

### Load in Chrome

1. Open `chrome://extensions/`
2. Enable "Developer mode"
3. Click "Load unpacked"
4. Select the `dist/` directory

### Development Notes

- Service worker hot-reload may be flaky - reload extension manually
- Content script changes require page refresh
- Popup changes hot-reload automatically
- Check service worker console for VectorDB logs

## API Requirements

The extension requires an OpenAI-compatible API endpoint that supports:

- Streaming responses (SSE)
- POST `/chat/completions` endpoint
- Standard OpenAI request/response format

Example compatible APIs:

- OpenAI API
- Anthropic API (via proxy)
- Local LLM servers (LM Studio, Ollama with openai-compatible mode)
- Custom proxy servers

## Future Enhancements

See `CONVERSATION_MODE_PLAN.md` for planned features:

- Multi-turn conversations with context
- Misinformation detection
- Better discussion site support (HN, Reddit)
- Dark mode
- Settings page
- Additional export formats

## License

See LICENSE file for details.

## Contributing

Contributions welcome! Please ensure:

- TypeScript types are properly defined
- CSS modules are used for styling
- Follow existing code structure
- Test in both popup and spotlight modes
- Verify keyboard shortcuts work
